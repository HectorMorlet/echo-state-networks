% !TEX root = ../HonoursThesis.tex

\chapter{Conclusion}

This thesis investigated the potential of integrating ordinal partition analysis into ESN architectures to enhance their predictive capabilities for chaotic time series. The core hypothesis was that incorporating ordinal patterns—either to guide readout selection or to structure the reservoir and input routing—could lead to ESN models that more accurately capture and predict complex dynamics. To this end, two novel architectures were proposed and evaluated: the Ordinal Partition-based Readout Switching ESN (ORSESN) and the Ordinal Partition ESN (OPESN).

\section{Key findings}

The ORSESN architecture, which employed ordinal partitions of the input to switch between different readout vectors, demonstrated notable improvements over traditional ESNs, particularly for medium to long-term prediction horizons across various chaotic systems (Lorenz, Rössler, and Mackey-Glass). For iterative prediction, while traditional ESNs often performed better for single-step predictions, the ORSESN, especially with higher ordinal pattern dimensions ($m=3$ or $m=4$), consistently achieved lower Root Mean Squared Error (RMSE) and greater prediction stability (lower variance across trials) as the number of prediction steps increased. This was particularly evident in the Lorenz and Rössler systems. For the Mackey-Glass system, ORSESN with m=4 showed substantially superior performance across almost all iterative prediction horizons. Direct prediction results largely mirrored these findings, with ORSESN models (particularly with $m=4$) outperforming traditional ESNs for longer forecasts. This suggests the ORSESN's advantage is not merely an artefact of error accumulation in iterative predictions but reflects an enhanced ability to model the underlying system dynamics. We are led to believe that the predictive advantage of the ORSESN was indeed conferred by the ordinal partition information guiding the readout selection, rather than the mere presence of a multi-readout gating mechanism. Furthermore, while ORSESN models appeared slightly less resilient to increasing noise levels in terms of relative RMSE increase, their absolute mean RMSE often remained lower than or comparable to traditional ESNs across tested noise levels ($\alpha\in[0.0,1.0]$).

The OPESN architecture, which used ordinal partitions to route input to distinct sub-reservoirs and explored various inter-sub-reservoir connection strategies, yielded more mixed results. For the Lorenz system, the OPESN showed only marginal and inconsistent improvements over traditional ESNs on the Lorenz system, with benefits diminishing with longer time steps. On the Rössler system, OPESN with $m=3$ offered some improvement for longer prediction horizons in both iterative and direct prediction; however, increasing $m$ to 4 degraded prediction performance. For the Mackey-Glass system, the OPESN (particularly with m=4) showed promise, achieving substantially lower RMSEs for longer iterative predictions and consistently better direct predictions with increasing m, similar to the ORSESN. Experiments with different sub-reservoir connection strategies (one-to-one, fully connected, scaled by transition probabilities, constant values, or disconnected) within the OPESN did not reveal a significantly superior connection method over simply using disconnected sub-reservoirs, suggesting that inter-sub-reservoir connections, as implemented, did not substantially enhance performance. The input routing mechanism, when driven by random selection instead of ordinal partitions, generally hindered OPESN performance, indicating that while ordinal information is valuable, the specific architectural choices of the OPESN does not optimally exploit this information, or that the architecture itself introduces complexities that can degrade performance.

The particularly strong performance of both ORSESN and OPESN (especially with $m=4$) on the Mackey-Glass series, when compared to the traditional ESN, may be attributed to the inherent nature of the Mackey-Glass system as a delay-differential equation. The Mackey-Glass equation is a scalar delay differential system whose derivative at time $t$ depends directly on $x(t-\tau)$. Ordinal patterns constructed with embedding delay $\tau$ encode whether recent samples are rising, falling, or stationary, thereby summarising the lagged information most relevant to the dynamics. When $m$ and $\tau$ are chosen appropriately, ORSESN can switch readouts and OPESN can route activations based on these patterns, effectively specialising on distinct local contexts. A conventional ESN can still capture delay effects through its evolving state, but it does so without an explicit symbolic representation, which may explain the stronger results observed for the variants based on ordinal partitions.

% The future evolution of such systems depends explicitly on past states over a specific delay period. Ordinal partitions, by construction with an ordinal pattern dimension $m$ and delay $\tau$, are adept at capturing the local temporal structure and short-term history of a time series. The resulting ordinal patterns may symbolise the relevant historical information that governs the Mackey-Glass dynamics. The ORSESN, by switching readout vectors based on these patterns, may potentially learn specialized predictive rules for different historical information. Similarly, the OPESN, by routing inputs to pattern-specific sub-reservoirs, allows these modules to potentially attune to the dynamics following particular past sequences. In contrast, a traditional ESN must implicitly learn these delay-dependent relationships solely through its recurrent dynamics. The explicit encoding of relevant local history via ordinal partitions may provide an effective feature for predicting systems like Mackey-Glass.

\section{Contributions and implications}

This research makes several contributions to the field of reservoir computing and time series prediction. Firstly, we designed and implemented two novel ESN architectures, ORSESN and OPESN, that explicitly integrate ordinal partition information. Secondly, we empirically validated these architectures against traditional ESNs on well-known chaotic attractors, demonstrating that ordinal-feature-guided ESNs, particularly the ORSESN, can offer significant performance improvements, especially for longer-term predictions. Thirdly, the findings highlight the utility of ordinal patterns as an interpretable, data-derived feature for enhancing ESNs; the ORSESN's success suggests that gating the readout mechanism based on local temporal orderings is a promising strategy. Lastly, the study provides insights into the impact of design parameters, such as ordinal pattern dimension ($m$) and delay ($\tau$), and architectural choices on model performance.

\section{Limitations and further research}

\begin{itemize}
    \item The current OPESN architecture assigns a sub-reservoir to each observed partition, which for higher $m$ can lead to a very large number of sub-reservoirs, many potentially associated with rare patterns and trained on limited data. Strategies for handling rare patterns, grouping similar ordinal patterns or growing the network to accomodate unseen ordinal patterns could be beneficial.
    \item The ORSESN gates the predictions generated by each readout by selecting only the relevant ordinal partition, however a weighted combination based on ordinal transition probabilities could be investigated.
    \item The thesis explored specific ways of integrating ordinal patterns, but other integration methods - such as using ordinal transition probabilities to modulate reservoir dynamics or directly feeding ordinal symbols as auxiliary inputs to a standard ESN - could be investigated.
    \item The investigation of OPESN sub-reservoir connections was not exhaustive; more sophisticated connection strategies, potentially learned or dynamically adapted, could be explored.
    \item The study primarily focused on single-component time series. Extending these architectures to multi-dimensional time series, perhaps by using multi-dimensional ordinal patterns or routing different dimensions to specialized sub-reservoirs in an OPESN-like structure, would be a valuable next step.
    % \item The selection of ordinal parameters ($m$ and $\tau$) was based on empirical testing for each dataset. Developing adaptive or automated methods for selecting optimal ordinal parameters could enhance the models' practicality.
    \item Further theoretical analysis into why and how ordinal-guided architectures improve prediction, particularly the stability observed in ORSESN with $m=4$, would deepen understanding.
    % \item More extensive testing for spectral radius $\rho$ and sparsity $d$, and the introduction of leakage could evaluate how these results generalise across parameter settings.
    \item Testing these architectures on a broader range of real-world datasets from different domains would further validate their generalizability and practical utility.
\end{itemize}

In conclusion, this thesis has demonstrated that ordinal partitions can serve as an effective predictive feature for enhancing echo state networks. The ORSESN stands out as a particularly effective architecture, offering improved accuracy and stability for chaotic time series forecasting. While the OPESN showed more modest results, the underlying principle of using ordinal information to structure reservoir computation remains a promising area for continued exploration. Future work building upon these foundations has the potential to further advance the capabilities of reservoir computing for complex time series analysis.
