\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {2.1}{\ignorespaces A diagram of an echo state network. The points labeled $\mathbf {x}(t)$ and $\mathbf {\hat {y}}(t)$ are the input and prediction respectively. The other points represent the states $\mathbf {s}(t)$ of the network. The lines represent the multiplications of the weighting vectors with $\mathbf {x}(t)$ and $\mathbf {s}(t)$ in equation \ref {eq:esn_state_update}.}}{7}{figure.caption.7}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A general diagram of a MOE model. Each expert $E_i(x)$ is weighted by $\pi _i$ for a given input $x$ for $i \in 1...K$.}}{12}{figure.caption.10}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces $\mathbf {W}_{rec}$ of ESN variants with sequential, feed-forward sub-reservoirs.}}{16}{figure.caption.12}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces $\mathbf {W}_{rec}$ of ESN variants with parallel sub-reservoirs.}}{17}{figure.caption.13}%
\addvspace {10pt}
\contentsline {figure}{\numberline {3.1}{\ignorespaces A visualisation of all 6 possible ordinal partitions when $m=3$.}}{21}{figure.caption.16}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces A time series with data points colour-coded by ordinal partition.}}{22}{figure.caption.17}%
\addvspace {10pt}
\contentsline {figure}{\numberline {4.1}{\ignorespaces Illustration of (a) Iterative and (b) Direct Prediction using an ESN, where the input data points are coloured black and the predictions are orange.}}{27}{figure.caption.28}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Time series plot of some true and predicted values. The start of each chunk is marked with a dot, where the ESN changes from being driven by the true signal to being driven by its own predictions.}}{29}{figure.caption.29}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Time series data used in the prediction experiments, each simulated and then corrupted by additive noise $\epsilon \sim \mathcal {N}(0,(0.1\,\sigma )^2)$, where $\sigma $ is the measured standard deviation of the time series component.}}{31}{figure.caption.31}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Prediction RMSE for the ORSESN as a function of the partition delay size $\tau $, with training data additive noise $\alpha =0.1$ and reservoir size $k=468$. Subfigures (a) and (b) correspond to iterative and direct prediction, respectively. Curves correspond to different numbers of prediction steps, and each axis represents an ORSESN with a different value for $m$.}}{33}{figure.caption.34}%
\addvspace {10pt}
\contentsline {figure}{\numberline {5.1}{\ignorespaces Mean iterative prediction RMSE for the ORSESN on the Lorenz $x$-component time series with additive noise $\alpha =0.1$ and total reservoir size $k=500$. Subfigure (a) shows results for time step size $\Delta t=0.01$, delay $\tau =20$ for all $m$; subfigure (b) shows results for time step size $\Delta t=0.05$, delays $\tau =10,10,4$ for $m=2,3,4$, respectively. Standard deviations between trials are represented by vertical bars and shaded regions indicate the full range of trial results.}}{40}{figure.caption.41}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces Mean direct prediction RMSE for the ORSESN on the Lorenz $x$-component time series with additive noise $\alpha =0.1$ and total reservoir size $k=500$. Subfigure (a) shows results for time step size $\Delta t=0.01$, delay $\tau =20$ for all $m$; subfigure (b) shows results for time step size $\Delta t=0.05$, delay $\tau =4$ for all $m$. Standard deviations between trials are represented by vertical bars and shaded regions indicate the full range of trial results.}}{42}{figure.caption.43}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Mean iterative prediction RMSE for the ORSESN for R\"ossler $x$ component time series with time step size $\Delta t=0.1$ and additive noise $\alpha =0.1$, delay $\tau =20$ and total reservoir size $k=500$. The standard deviations between trials are represented by vertical bars and the range of trial results is represented by the shaded regions.}}{44}{figure.caption.46}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Iterative free-run predictions for the RÃ¶ssler system ($x$ component) with time step size $\Delta t=0.1$. The figure compares the traditional ESN with ORSESN models of varying ordinal pattern dimensions ($m=2,3,4$) over 200 prediction steps. All models were configured with a delay $\tau =20$, additive noise $\alpha =0.1$, and a total reservoir size $k=500$. Each grey vertical line indicates the beginning of prediction chunk, where the echo state network changes from being driven by the true signal to being driven by its own predictions.}}{45}{figure.caption.47}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces Mean direct prediction RMSE for the ORSESN for R\"ossler $x$ component time series with time step size $\Delta t=0.1$ and additive noise $\alpha =0.1$, delay $\tau =20$ and total reservoir size $k=500$. The standard deviations between trials are represented by vertical bars and the range of trial results is represented by the shaded regions.}}{46}{figure.caption.48}%
\contentsline {figure}{\numberline {5.6}{\ignorespaces Iterative prediction RMSE for the ORSESN for Mackey-Glass time series with $\Delta t=0.5$, delay $\tau =20$, additive noise $\alpha =0.1$ and total reservoir size $k=500$. The standard deviations between trials are represented by vertical bars and the range of trial results is represented by the shaded regions.}}{47}{figure.caption.50}%
\contentsline {figure}{\numberline {5.7}{\ignorespaces Example of iterative prediction for the Mackey-Glass system ($\Delta t=0.5$, additive noise $\alpha =0.1$). Predictions from the traditional ESN ($m=1, \tau =1$) and ORSESN ($m \in \{2,3,4\}, \tau =20$) are compared against the true series. All models use a total reservoir size $k=500$. Each grey vertical line indicates the beginning of prediction chunk, where the echo state network changes from being driven by the true signal to being driven by its own predictions.}}{48}{figure.caption.51}%
\contentsline {figure}{\numberline {5.8}{\ignorespaces Mean direct prediction RMSE for the ORSESN for Mackey-Glass time series with $\Delta t=0.5$, delay $\tau =20$, additive noise $\alpha =0.1$ and total reservoir size $k=500$. The standard deviations between trials are represented by vertical bars and the range of trial results is represented by the shaded regions.}}{49}{figure.caption.52}%
\contentsline {figure}{\numberline {5.9}{\ignorespaces Mean iterative prediction RMSE across trials for the ORSESN on the Lorenz $x$-component time series with time step size $\Delta t=0.01$, delay $\tau =20$, additive noise $\alpha =0.1$, and total reservoir size $k=468$, compared to a variant that selects the readout randomly rather than by ordinal partition. Subfigures (a), (b), and (c) correspond to $m=2$, $m=3$, and $m=4$, respectively. Standard deviations between trials are represented by vertical bars and shaded regions indicate the full range of trial results.}}{50}{figure.caption.54}%
\contentsline {figure}{\numberline {5.10}{\ignorespaces Mean direct prediction RMSE across trials for the ORSESN on the Lorenz $x$-component time series with time step size $\Delta t=0.01$ as a function of simulated data noise level $\alpha $, with delay $\tau =20$ and total reservoir size $k=468$. Curves correspond to different numbers of prediction steps, and each panel represents an ordinal pattern dimension $m$ (with $m=1$ denoting the traditional ESN).}}{51}{figure.caption.56}%
\contentsline {figure}{\numberline {5.11}{\ignorespaces Mean iterative prediction RMSE across trials for the ORSESN on the Lorenz $x$-component time series with time step size $\Delta t=0.01$ as a function of simulated data noise level $\alpha $, with delay $\tau =20$ and total reservoir size $k=468$. Curves correspond to different numbers of prediction steps, and each panel represents an ordinal pattern dimension $m$ (with $m=1$ denoting the traditional ESN).}}{52}{figure.caption.57}%
\addvspace {10pt}
\contentsline {figure}{\numberline {6.1}{\ignorespaces Architecture of the ordinal partition echo state network (OPESN). The reservoir is partitioned into $N_{obs}$ sub-reservoirs of size $k$. Input $\mathbf {x}(t)$ is routed to the active sub-reservoir based on the ordinal partition $\pi _t$ (colour coded), and a single global readout $\mathbf {C}_{\text {out}}$ produces $\mathbf {y}(t)$.}}{55}{figure.caption.59}%
\contentsline {figure}{\numberline {6.2}{\ignorespaces Visualisations of the recurrence matrix $\mathbf {W}_{rec}$ under six connection schemes for a hypothetical OPESN with three partitions: (a) one-to-one weighted by $p_{ij}$; (b) constant one-to-one; (c) fully connected weighted by $p_{ij}$; (d) constant fully connected; (e) disconnected; and (f) sparsely connected. Shading intensity reflects relative weight magnitudes and internal weights for each sub-reservoir are colour-coded.}}{58}{figure.caption.62}%
\contentsline {figure}{\numberline {6.3}{\ignorespaces OPESN state masking prior to readout. Only the $k$ states of the active sub-reservoir (purple) remain; all other states are zeroed before applying $\mathbf {C}_{\text {out}}$.}}{60}{figure.caption.65}%
\contentsline {figure}{\numberline {6.4}{\ignorespaces Mean iterative prediction RMSE for the OPESN on the Lorenz $x$ component time series with additive noise $\alpha =0.1$ and reservoir size $k\approx 500$. (a) $\Delta t = 0.01$, delays $\tau =20$ for $m=2,3,4$; (b) $\Delta t = 0.05$, delays $\tau =10,10,4$ for $m=2,3,4$. Vertical bars show standard deviations; shaded regions show full range.}}{62}{figure.caption.67}%
\contentsline {figure}{\numberline {6.5}{\ignorespaces Mean direct prediction RMSE for the OPESN on the Lorenz $x$ component time series with additive noise $\alpha =0.1$ and reservoir size $k\approx 500$. (a) $\Delta t = 0.01$, delays $\tau =20$ for $m=2,3,4$; (b) $\Delta t = 0.05$, delays $\tau =4$ for $m=2,3,4$. Vertical bars show standard deviations; shaded regions show full range.}}{63}{figure.caption.69}%
\contentsline {figure}{\numberline {6.6}{\ignorespaces Mean iterative prediction RMSE for the OPESN on the RÃ¶ssler $x$ component time series ($\Delta t = 0.1$, $\alpha =0.1$, $k\approx 500$). Delays $\tau =20,20,10$ for $m=2,3,4$, respectively. Vertical bars show standard deviations; shaded regions show full range.}}{64}{figure.caption.71}%
\contentsline {figure}{\numberline {6.7}{\ignorespaces Mean direct prediction RMSE for the OPESN on the RÃ¶ssler $x$ component time series ($\Delta t = 0.1$, $\alpha =0.1$, $k\approx 500$). Delays $\tau =10,20,10$ for $m=2,3,4$, respectively. Vertical bars show standard deviations; shaded regions show full range.}}{65}{figure.caption.72}%
\contentsline {figure}{\numberline {6.8}{\ignorespaces Mean iterative prediction RMSE for the OPESN on the Mackey-Glass time series ($\Delta t = 0.5$, $\alpha =0.1$, $k\approx 500$). Delay $\tau =20$ for all $m=2,3,4$. Vertical bars show standard deviations; shaded regions show full range.}}{66}{figure.caption.74}%
\contentsline {figure}{\numberline {6.9}{\ignorespaces Mean direct prediction RMSE for the OPESN on the Mackey-Glass time series ($\Delta t = 0.5$, $\alpha =0.1$, $k\approx 500$). Delay $\tau =20$ for all $m=2,3,4$. Vertical bars show standard deviations; shaded regions show full range.}}{67}{figure.caption.75}%
\contentsline {figure}{\numberline {6.10}{\ignorespaces Mean iterative prediction RMSE on the Lorenz $x$ component ($\Delta t=0.01$, $\alpha =0.1$, $k=468$) comparing OPESN input routing by ordinal partition versus random routing, for delays $\tau =20$ and $m=2,3,4$ in subfigures (a)-(c). Vertical bars show standard deviations; shaded regions show full range.}}{69}{figure.caption.77}%
\contentsline {figure}{\numberline {6.11}{\ignorespaces Mean iterative prediction RMSE on the Lorenz $x$ component ($\Delta t=0.01$, $\alpha =0.1$, $k=468$) for OPESN variants of sub-reservoir connectivity. Delay $\tau =20$, $m=4$. Dashed black line is the disconnected baseline; vertical bars show its standard deviation.}}{70}{figure.caption.79}%
\contentsline {figure}{\numberline {6.12}{\ignorespaces Mean direct prediction RMSE as a function of noise level $\alpha \in [0,1]$ for the OPESN on the Lorenz $x$ component ($\Delta t=0.01$, delay $\tau =20$, $k=468$). Curves are for lengths of prediction 1, 20, 50 and 100 steps; panels correspond to $m=1$-$4$.}}{71}{figure.caption.81}%
\contentsline {figure}{\numberline {6.13}{\ignorespaces Iterative prediction RMSE as a function of noise level $\alpha \in [0,1]$ for the OPESN on the Lorenz $x$ component ($\Delta t=0.01$, delay $\tau =20$, $k=468$). Curves are for lengths of prediction 1, 20, 50 and 100 steps; panels correspond to $m=1$-$4$.}}{71}{figure.caption.82}%
\addvspace {10pt}
\addvspace {10pt}
\contentsline {figure}{\numberline {A.1}{\ignorespaces Recursive prediction RMSE for the OPESN for all variants of sub-reservoir connections. Delay $\tau =20$, $m=3$, noise level $\alpha =0.1$, and total reservoir size $k=468$.}}{77}{figure.caption.85}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Direct prediction RMSE for the OPESN for all variants of sub-reservoir connections. Delay $\tau =20$, $m=4$, noise level $\alpha =0.1$, and total reservoir size $k=468$.}}{78}{figure.caption.86}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Direct prediction RMSE for the OPESN for all variants of sub-reservoir connections. Delay $\tau =20$, $m=3$, noise level $\alpha =0.1$, and total reservoir size $k=468$.}}{79}{figure.caption.87}%
